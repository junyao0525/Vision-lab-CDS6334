{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f843aa34",
   "metadata": {
    "id": "f843aa34"
   },
   "source": [
    "# Lab 10-ML Pipeline and Neural Network\n",
    "\n",
    "As an important precursor to understanding neural networks or even deep learning, it is essential to understand how Machine Learning (ML) works.\n",
    "\n",
    "## The Machine Learning Pipeline\n",
    "\n",
    "Machine learning is literally 'getting the machine to learn something', and that involves putting something \"in\" to the machine and expecting something \"out\" of the machine. What happens inside the machine? Well, we expect that the machine would know how to \"learn\". In actual fact, we have to tell the machine how we want it to learn, and provide the necessary methods and data. Basically, we define the algorithm that would do the job on the data. Machine learning *lives* on data; it is data-driven and therefore, the data (think of food) that we put in also matter a lot. All these steps are part of what we call a **machine learning pipeline**. \n",
    "\n",
    "In this first session, we will be making a quick journey across the machine learning pipeline, and attempt to understand some important nuts and bolts that are involved in the entire process.\n",
    "\n",
    "---\n",
    "We start of by getting our hands on an image dataset consisting of many samples of surface defects, categorized by its type. This dataset was originally collected by [Northeastern University, China](http://faculty.neu.edu.cn/yunhyan/NEU_surface_defect_database.html) and was made publicly available for research and non-commercial usage. <br>\n",
    "The dataset is provided in the `NEU-CLS-64.zip` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d12755",
   "metadata": {
    "id": "60d12755"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584af3f5",
   "metadata": {
    "id": "584af3f5"
   },
   "outputs": [],
   "source": [
    "#extract the dataset to the current working directory\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"NEU-CLS-64.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e21694",
   "metadata": {
    "id": "17e21694"
   },
   "source": [
    "Explore the files in the directory structure. You will notice there are 9 sub-directories. These correspond to the 9 categories of surface defects compiled by Northeastern University for their research. However, 3 of these categories ('gg', 'rp', and sp') have lesser samples compared to the other 6, so they will not be considered for now. These 6 categories have at least 774 images, while the omitted 3 categories have at most 439 images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e98f29d",
   "metadata": {
    "id": "3e98f29d"
   },
   "source": [
    "### Preparation\n",
    "\n",
    "Before we start identifying what data (or features) that we intend to use, we need to lay down a few 'ground rules' based on what a typical machine learning pipeline would do.\n",
    "\n",
    "1. For each of these 6 categories, we need to partition the data into two non-overlapping sets: a training set and a test set\n",
    "2. We could see that the categories are all different sizes. For simplicity and fair learning (for now), let's use the same number of samples for these 6 categories. The largest possible number of samples per category that we can use is equals to the size of the smallest category (makes sense?). Let's make that $N$.\n",
    "3. We could try pick these images at random. But again, for ease, we will just sample the first $N$ images in sequence, from each category. The images are already numbered in sequence from 1, so this allows easy looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cf61a",
   "metadata": {
    "id": "fa1cf61a"
   },
   "outputs": [],
   "source": [
    "# make a list of tuples to that we can later use to refer back to the actual category names\n",
    "# slightly against the idea of a dictionary, since we want fixed index access here\n",
    "# tuples also immutable to prevent any possible overwrites\n",
    "cats = [('cr', 'crazing'), \n",
    "        ('in', 'inclusion'),        \n",
    "        ('pa', 'patches'),\n",
    "        ('ps', 'pitted surface'),\n",
    "        ('rs', 'rolled-in scale'),\n",
    "        ('sc', 'scratches')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d36b91",
   "metadata": {
    "id": "e5d36b91"
   },
   "outputs": [],
   "source": [
    "# construct a loop to read all images in a folder into some variable. \n",
    "# How would you store it?\n",
    "# ...a list of 2-D arrays?\n",
    "# ...an array of 2-D arrays, or 3D?\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob('./NEU-CLS-64/cr/*.jpg'): #assuming jpg\n",
    "    im = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)   # let's load in grayscale\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b657b38",
   "metadata": {
    "id": "3b657b38"
   },
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img,cmap='gray',vmin=0,vmax=255), plt.title('Sample Image')\n",
    "    plt.xticks([]), plt.yticks([]), plt.show()\n",
    "showImage(image_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6ad17",
   "metadata": {
    "id": "cdd6ad17"
   },
   "source": [
    "Create a database with the images and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a9a16",
   "metadata": {
    "id": "069a9a16"
   },
   "outputs": [],
   "source": [
    "image_db = []\n",
    "for c in cats:  \n",
    "    image_list = []\n",
    "    path = './NEU-CLS-64/'+ c[0] +'/*.jpg'\n",
    "    for filename in glob.glob(path):\n",
    "        im = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        image_list.append(im)\n",
    "    image_db.append(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1c24a",
   "metadata": {
    "id": "39e1c24a"
   },
   "outputs": [],
   "source": [
    "print(len(image_db))\n",
    "# print(image_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a179cf1",
   "metadata": {
    "id": "0a179cf1"
   },
   "source": [
    "Let's proceed with slicing these inner lists into equal portions. Let's go with 500 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f1828",
   "metadata": {
    "id": "043f1828"
   },
   "outputs": [],
   "source": [
    "image_db_fair = [ic[:500] for ic in image_db]\n",
    "print(len(image_db_fair[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36408354",
   "metadata": {
    "id": "36408354"
   },
   "source": [
    "Now, prepping for supervised machine learning involves creating two portions: the *data*, and the *labels*. As rule of thumb for ML, we want these to be formatted into an $N\\times M$ 2-D array (or list), consisting of $N$ number of samples and $M$ number of feature dimensions. \n",
    "\n",
    "### Data\n",
    "We can treat each pixel as a feature. Since each image is 64x64 in size (we read them in grayscale), it can be vectorized into a 4096-value vector. So, with 6 categories and 500 images/category, we are expecting a *3000x4096* data array. This the so-called $X$ array in ML which is representative of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a9b62",
   "metadata": {
    "id": "a55a9b62"
   },
   "outputs": [],
   "source": [
    "# check shape of image. this is the first image of the first category. all ok?\n",
    "w, h = image_db_fair[0][0].shape\n",
    "print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b78599",
   "metadata": {
    "id": "e4b78599"
   },
   "outputs": [],
   "source": [
    "image_db_fair[0][0].reshape(1, w*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc87c7",
   "metadata": {
    "id": "51dc87c7"
   },
   "outputs": [],
   "source": [
    "image_db = []\n",
    "w, h = image_db_fair[0][0].shape\n",
    "for img_c in image_db_fair:\n",
    "    for im in img_c:\n",
    "        image_db.append(im.reshape(1, w*h))\n",
    "    \n",
    "image_db = np.squeeze(np.array(image_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c843f1",
   "metadata": {
    "id": "54c843f1"
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(image_db)\n",
    "print(image_db.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306d93d",
   "metadata": {
    "id": "5306d93d"
   },
   "source": [
    "### Labels\n",
    "\n",
    "For labels, we can generate them from the way our folders are structured, the first 500 can be labeled 'cr', the next 500 be labeled 'in' and so on. As such, we are expecting a 3000x1 label array. This is the $y$ array, or rather a vector in ML which is representative of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a68fce",
   "metadata": {
    "id": "d8a68fce"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for c in cats:\n",
    "    labels.extend([c[0] for i in range(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9183738",
   "metadata": {
    "id": "c9183738"
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(labels[0])    # should be cr\n",
    "print(labels[999])  # should be in\n",
    "print(labels[1000]) # should be pa\n",
    "print(labels[2999]) # should be sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51af85",
   "metadata": {
    "id": "2e51af85"
   },
   "outputs": [],
   "source": [
    "# make it an array\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba6427",
   "metadata": {
    "id": "91ba6427"
   },
   "source": [
    "-----------------------------------\n",
    "### Partitioning Data\n",
    "\n",
    "Next, let's partition these folders into training and test set. We could do this labourously, using some kind of index randomizer and then slice the randomly-arranged indices into two halves. Or, we could just make use of a function from **scikit-learn** plainly called `train_test_split`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf3ea6",
   "metadata": {
    "id": "b2bf3ea6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655331f7",
   "metadata": {
    "id": "655331f7"
   },
   "outputs": [],
   "source": [
    "# make sure the sizes make sense, and that they are both same type (arrays)\n",
    "print(image_db.shape)    # X     (data)\n",
    "print(labels.shape)      # y    (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9a104",
   "metadata": {
    "id": "92f9a104"
   },
   "outputs": [],
   "source": [
    "# this splits both X and Y into their respective train and test partitions\n",
    "# by default, test_size=0.25 which means 25% of data is in the test set, while\n",
    "# the training set has the remaining 75%. This ratio can be tweaked\n",
    "# random_state ensures that the splitting is done using the same randomizer seed (for reproducibility)\n",
    "\n",
    "X = image_db\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d344fb",
   "metadata": {
    "id": "33d344fb"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)  # this should be same # samples as X_train\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)  # this should be same # samples as X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612c731",
   "metadata": {
    "id": "9612c731"
   },
   "source": [
    "---\n",
    "### Classification\n",
    "\n",
    "The end goal of supervised learning, particularly a classification task is to learn a bunch of weights (or parameters) $W$ from data $X$ with the aid of known labels $y$ by an optimization process such that it can enable us to make categorical predictions $y'$ on new samples $X'$. We can summarize this generally as a hypothesis :\n",
    "\\begin{align}\n",
    "  H(X) = W^T X = y\n",
    "\\end{align}\n",
    "where $W$ has been optimized by minimizing the objective function:\n",
    "\\begin{align}\n",
    "  J = \\sum_{i=1}^{N}(H(X)-y_{i})^2\n",
    "\\end{align}\n",
    "\n",
    "Different classifiers are governed by slightly different hypothesis, which in turn, results in a slightly different objective function. For example, a simple logistic regression (LR) classifier, passes this same hypothesis thru a \"logistic function\" $\\phi$, which converts raw values into probability values lying in the [0, 1] range.\n",
    "\\begin{align}\n",
    "  H(X) = \\phi(W^T X)\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-7c9b7670c90b286160a88cb599d1b733\" style=\"text-align:center\" width=400 />''\n",
    "\n",
    "Probability (for 2-class problem) is 0.5, which is when $W^T X=0$. So, this changes how the objective function behave. Basically, we can now perform classification simply by looking into whether $H(X) \\approx 1$ (that is, it belongs to category $y=1$) or $H(X) \\approx 0$ (that is, it belongs to category $y=0$).\n",
    "\n",
    "But this seems to be applicable only when there are 2 categories? How then does this extend to a multi-class situation  with more than 2 classes?\n",
    "\n",
    "#### **One-vs-rest (or one-vs-all)** \n",
    "\n",
    "To resolve cases with $N$ classes, we can use **one-vs-rest** mode which learns $N$ number of models for each category against all other categories grouped. In other words, if we have $N$ categories, we train $N$ number of classifiers, as illustrated below (courtesy of Andrew Ng's course):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w3_logistic_regression_regularization/multiclass_classification2.png\" width=450 />\n",
    "\n",
    "To make a prediction on a new input $X'$, choose the class that maximizes the hypothesis (in the example above, $h$, in ours $H$)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318cd8b0",
   "metadata": {
    "id": "318cd8b0"
   },
   "source": [
    "#### **Fit, predict, score**\n",
    "\n",
    "Let's use scikit-learn's built-in [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Most machine learning models in scikit-learn follow the same set of standard API methods (except for a few special cases), all of them have `fit()`, `predict()` and `score()`.\n",
    "* `fit()`: does the learning or 'training' if you wish to call it\n",
    "* `predict()`: performs prediction on samples (can be from train set, test set or even new data)\n",
    "* `score()`: performs prediction on a set of samples, and computes the performance metric. Most classifiers come with a pre-fixed metric that is typically used. But you can choose your own metric from their [`metrics`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dc840",
   "metadata": {
    "id": "1f8dc840"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "###Note: This cell may take awhile to run\n",
    "# create the classifier object\n",
    "clf = LogisticRegression(solver='sag', n_jobs=-1, max_iter=100)    \n",
    "# 'sag' use l2 optimization, '-1' use all processors, default max iteration\n",
    "clf.fit(X_train, y_train)     # fit the model with training data/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57d783",
   "metadata": {
    "id": "cd57d783"
   },
   "outputs": [],
   "source": [
    "print(\"Training set accuracy:\", clf.score(X_train, y_train)) \n",
    "print(\"Test set accuracy\", clf.score(X_test, y_test)) \n",
    "\n",
    "# Using .predict() and classification metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229e38e",
   "metadata": {
    "id": "5229e38e"
   },
   "source": [
    "Here's a typical phenomenon in machine learning. We train a classifier/model on some training data. That same classifier is then used to make predictions on unseen test data (hence, no overlapping earlier when we partition). Here are several insights:\n",
    "\n",
    "* The test set performance is usually lower than the training set performance.\n",
    "* The training set performance also tells us whether we are fitting the data well or not.\n",
    "\n",
    "What do you think of the results?\n",
    "\n",
    "What do you think may be \"bias\" in this machine learning process?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8652d6",
   "metadata": {
    "id": "3b8652d6"
   },
   "source": [
    "### Cross-validation\n",
    "\n",
    "Cross-validation is a way of making sure that we have got \"all grounds covered\". It's perhaps not convincing to rely on a single way of splitting the data. The way we split could be unintentionally (or even intentionally) bias , for e.g. we could get really lucky with a nice training set or we could be unlucky as well. \n",
    "\n",
    "One common technique is to ensure that every sample in the dataset gets to be tested at least once. **k-fold cross validation** partitions the data into *k* number of partitions. Each partition takes turn to be the test set, while the remaining *k-1* partitions become the training set. In the end, the results from all *k* folds are averaged. Basically, e.g. a 5-fold cross validation will be repeated 5 times, with a 80:20 training-test ratio, and the results from all 5 folds averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb087c",
   "metadata": {
    "id": "18fb087c"
   },
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "# Note: will take time to run as multiple models are trained and tested\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# since clf has been created, we can re-use it\n",
    "# by default, k=5 if not set\n",
    "# we set to k=4 to mimic the earlier 75:25 setup\n",
    "res = cross_validate(clf, X, y, cv=4)\n",
    "print(res['test_score'])\n",
    "print(\"Average accuracy:\", res['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778b5e7",
   "metadata": {
    "id": "5778b5e7"
   },
   "source": [
    "You could play with several parameters: the *C* value (regularization term), the *solver* (optimization method, some converge slower, some faster), *class_weight* parameter (give stronger influence to smaller classes, for imbalance data), the *norm* used in the regularization (default is L2 norm, can be L1 for sparser data).\n",
    "\n",
    "There's a more mechanistic way of getting this tedious job done. That is called a [**grid search**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). It basically searches through all possible permutations of different parameter values, and returns all computed results, and also the best parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed3273",
   "metadata": {
    "id": "62ed3273"
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "So, besides having accuracy scores, we also want to know which category did well and which did not. A **confusion matrix** is most useful here. It shows a square matrix containing the number of ground-truth (desired) labels on one side and the number of predicted labels on the other side. So what it tells us is how many were correctly predicted (on the diagonals) and how many were incorrectly predicted (elsewhere), and when they were incorrect, which other category they went to. \n",
    "\n",
    "`scikit-learn` also has a **classification report** which gives us a bunch of class-based metrics such as the precision, recall and f1-score for each class. It's a good way to have a broad overview of how each class is performing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e064bcb",
   "metadata": {
    "id": "0e064bcb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "short_labels = [i[0] for i in cats]\n",
    "\n",
    "print(\"Test Accuracy: \", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Confusion Matrix\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "n_samples = np.sum(cm, axis=1)\n",
    "dcm = [cm[i]/n for i, n in enumerate(n_samples) ]\n",
    "print(cm)\n",
    "print(\"Normalized Confusion Matrix\")\n",
    "print(np.squeeze(dcm))\n",
    "print(classification_report(y_test, y_pred, labels=short_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837acbc6",
   "metadata": {
    "id": "837acbc6"
   },
   "source": [
    "The `seaborn` package can visualize the results for better reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512286b",
   "metadata": {
    "id": "a512286b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(dcm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(short_labels); ax.yaxis.set_ticklabels(short_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54f9fd",
   "metadata": {
    "id": "4d54f9fd"
   },
   "outputs": [],
   "source": [
    "# let's pick some random images from the dataset and perform prediction to see\n",
    "# if they match the actual labels\n",
    "\n",
    "def checkPredictions(img_set, img_set_labels, img_shape, idx):\n",
    "    showImage(img_set[idx].reshape(img_shape[0], img_shape[1]))\n",
    "    print(\"Prediction:\",clf.predict(X_test[idx].reshape(1, -1)))  \n",
    "    print(\"G/T:\",img_set_labels[idx])  \n",
    "  \n",
    "  \n",
    "# remember that we shaped the images into a 1-D vector, we have to reshape it back\n",
    "actualsize = (64, 64)\n",
    "checkPredictions(X_test, y_test, actualsize, 12)\n",
    "checkPredictions(X_test, y_test, actualsize, 48)\n",
    "checkPredictions(X_test, y_test, actualsize, 101)\n",
    "checkPredictions(X_test, y_test, actualsize, 234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa0b5f",
   "metadata": {
    "id": "f6fa0b5f"
   },
   "source": [
    "### Other Features?\n",
    "\n",
    "Typically, we don't want to rely on pixels as features. They have a somewhat high degrees of freedom and is likely not scale-, rotation- or even translation-invariant. This can be a big problem since any small changes to the image might result in different ordering of pixels. \n",
    "\n",
    "Some other \"hand-crafted\" image features to consider besides using pixels: <A href=https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html>**HOG**</A>, **LBP**, or **SIFT+BOW**. Or perhaps, a simple **edge image** maybe be useful to understand the kinds of edges that exist in each of these defect types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29539a3",
   "metadata": {
    "id": "d29539a3"
   },
   "outputs": [],
   "source": [
    "# LBP features\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import data\n",
    "\n",
    "# settings for LBP\n",
    "radius = 1\n",
    "n_points = 8 * radius\n",
    "\n",
    "img = image_db[2553].reshape(64, 64)     # change index to view other images\n",
    "lbp = local_binary_pattern(img, n_points, radius)\n",
    "\n",
    "showImage(np.hstack((img, lbp)))\n",
    "\n",
    "lbphist = np.histogram(np.array(lbp, dtype='uint8'), bins=int(lbp.max()+1), density=True)\n",
    "plt.bar(range(int(lbphist[1].max())+1), lbphist[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214026a",
   "metadata": {
    "id": "e214026a"
   },
   "outputs": [],
   "source": [
    "# HOG features\n",
    "from skimage.feature import hog\n",
    "\n",
    "img = image_db[2553].reshape(64, 64)  \n",
    "fd, hog_img = hog(img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                  cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "print(fd.shape)\n",
    "showImage(np.hstack((img, hog_img*255.0)))\n",
    "plt.bar(range(len(fd)), fd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd9af2",
   "metadata": {
    "id": "56fd9af2"
   },
   "source": [
    "These features can be used to train the classifiers.\n",
    "\n",
    "**Q**: Try out some of these suggested features (HOG, LBP) to be used in the ML pipeline. Extract the features for all images and then put them through the same ML pipeline.\n",
    "\n",
    "What you can try is to test out different settings and features in machine learning and keep a log (or table) of the performance results. It helps a lot in making (or eliminating) decisions when it comes to finding the best method to be adopted\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|---|:-:|:-:|---|---|\n",
    "| **Features** | **Classifier** | **Accuracy (%)**  |   |   |\n",
    "| Raw pixels | LR |  ? |   |   |\n",
    "| HOG  | LR  | ?  |   |   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204b41e-b47e-42b4-a72b-eba04c6a157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bf4ad",
   "metadata": {
    "id": "ad8bf4ad"
   },
   "source": [
    "---\n",
    "## Neural Network\n",
    "\n",
    "A neural network is a machine learning technique that attempts to mimic the human brain by representing it with a series of connected nodes in different layers. It's not necessary to model the biological complexity of the human brain at a molecular level, just its higher level rules and \"thinking\" capabilities. \n",
    "\n",
    "### Implementing MLP with Keras\n",
    "To start doing that, we will use **MNIST**, a commonly used handwritten digit dataset consisting of 60,000 images in the training set and 10,000 images in the test set. Each digit has around 6,000 images in the training set. The digit images have been size-normalized and centered to a fixed size of 28×28 pixels. We are going to try implement a Multilayer Perceptron (MLP) neural network using the Keras library.\n",
    "\n",
    "The raw pixel values will be the input to the network. In preparation, we will reshape the image matrix to an array of dimension 784 (28*28) and feed it to the network as input. We will use a MLP with 2 hidden layers having 512 neurons each. The output layer will have 10 layers for the 10 digits. So, we are expecting the class labels to be one-hot encoded.\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/mlp-mnist-schematic.jpg\" width=500>\n",
    "\n",
    "Keras comes with a MNIST data loader, which downloads the data from its servers if you do not have it in your computer. We immediately divide the loaded data into the respective training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7cc5b",
   "metadata": {
    "id": "b2d7cc5b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist #keras attached with tensorflow\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c15ae9",
   "metadata": {
    "id": "10c15ae9"
   },
   "outputs": [],
   "source": [
    "# check out some information about the data shape\n",
    "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
    " \n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    " \n",
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[10,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_labels[10]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_images[10,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_labels[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07cb0c",
   "metadata": {
    "id": "7b07cb0c"
   },
   "source": [
    "Next, we will apply some pre-processing steps to make sure the feature matrix is formatted, data types are compatible and class labels are compatible with the 10-unit output layer of the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bb15e",
   "metadata": {
    "id": "184bb15e"
   },
   "outputs": [],
   "source": [
    "# Change from matrix of dim 28x28 to array of dim 784\n",
    "dimData = np.prod(train_images.shape[1:])\n",
    "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
    "test_data = test_images.reshape(test_images.shape[0], dimData)\n",
    "\n",
    "print(dimData, train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e832d",
   "metadata": {
    "id": "295e832d"
   },
   "outputs": [],
   "source": [
    "# Convert data to float and scale values between 0 and 1\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    " \n",
    "# Scale the data to range[0, 1]\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d6874",
   "metadata": {
    "id": "b18d6874"
   },
   "outputs": [],
   "source": [
    "# Convert the labels from integer to categorical (one-hot) encoding, it is the format required by Keras \n",
    "# to perform multiclass classification. \n",
    "# One-hot encoding is a type of boolean representation of integer data. \n",
    "# It converts the integer to an array of all zeros except a 1 at the index of the integer.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    " \n",
    "# Show the category label after one-hot encoding\n",
    "print('Original label 0 : ', train_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9555ab",
   "metadata": {
    "id": "fa9555ab"
   },
   "source": [
    "The following block diagram shows the Keras Workflow. Basically, once you have prepared the training and test data, you can follow these steps closely to train a neural network in Keras.\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/09/keras-workflow.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b8654",
   "metadata": {
    "id": "256b8654"
   },
   "source": [
    "### Constructing the network structure\n",
    "\n",
    "As mentioned earlier, we will be creating a neural network with 2 hidden layers and an output layer with 10 units. The number of units in the hidden layers is kept at 512. The input to the network is the 784-dimensional array converted from the 28×28 image.\n",
    "\n",
    "We will use the Sequential model for building the network. In the Sequential model, we can just stack up layers by adding the desired layer one by one. We use the **Dense** layer, also formally known as a fully connected (FC) layer where all the neurons from one layer are connected to the neurons in the previous layer. Apart from the Dense layer, we add the **ReLU** activation function which is required to introduce non-linearity to the model. This will help the network learn non-linear decision boundaries. The last layer is a **softmax** layer as it is a multiclass classification problem. For binary classification, we can use the sigmoid function.\n",
    "\n",
    "**Side notes**: \n",
    "1. Here's a classic response to the question of [\"How many hidden units should I use?\"](http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-10.html)\n",
    "2. Here is why ReLU is the [top choice](https://datascience.stackexchange.com/questions/23493/why-relu-is-better-than-the-other-activation-functions) among non-linear activation functions \n",
    "3. [Softmax vs. Sigmoid](https://stats.stackexchange.com/questions/233658/softmax-vs-sigmoid-function-in-logistic-classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de951f8",
   "metadata": {
    "id": "7de951f8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Input(shape=(dimData,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad83a4",
   "metadata": {
    "id": "4fad83a4"
   },
   "source": [
    "Next, we configure the network by choosing the optimizer. Here, we choose `'rmsprop'`. We also specify the loss type which is categorical cross entropy which is used for multiclass classification. We also specify the metrics (accuracy in this case) which we want to track during the training process. You can also try using any other optimizers such as `'adam'` or `'SGD'`, or try adding more types of metrics that you would like to keep track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a8f0f",
   "metadata": {
    "id": "089a8f0f"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a019a27",
   "metadata": {
    "id": "4a019a27"
   },
   "source": [
    "### TensorFlow Playground\n",
    " \n",
    "To understand the significance of hidden layers, perhaps you may want to visualize what actually happens in these layers. For this, you can check out an interactive platform from Google called [TensorFlow Playground](http://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=&seed=0.75972&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&playButton_hide=false), which is a web app that allows you to create and experiment with simple feedforward neural networks and see the effects of training in real time. You can play around by changing the number of hidden layers, number of units in a hidden layer, type of activation function, type of data, learning rate, regularization parameters etc\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/sample-playground-tensorflow.png\" width=500>\n",
    " \n",
    " \n",
    "### TensorBoard \n",
    "\n",
    "The computations you will use TensorFlow for -- like training a massive deep neural network, can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, a suite of visualization tools called TensorBoard is included when you install the TensorFlow package. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it. When TensorBoard is fully configured, it looks like this:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/mnist_tensorboard.png\" width=500>\n",
    "\n",
    "In the next example, we will explore how TensorBoard can be used to analyze and monitor the training of the network.\n",
    "\n",
    "For a more detailed explanation on how to use Tensor, please check out this tutorial on <a href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/get_started.ipynb#scrollTo=Gi4PaRm39of2\">Getting Started with Tensorboard.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0bafd",
   "metadata": {
    "id": "16b0bafd"
   },
   "source": [
    "### Using TensorBoard with Keras Model.fit()\n",
    "\n",
    "When training with Keras's [Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit), adding the `tf.keras.callbacks.TensorBoard` callback ensures that logs are created and stored. Additionally, enable histogram computation every epoch with `histogram_freq=1` (this is off by default)\n",
    "\n",
    "Place the logs in a timestamped subdirectory to allow easy selection of different training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d02341",
   "metadata": {
    "id": "30d02341"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime, os, time\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b64ce0",
   "metadata": {
    "id": "75b64ce0"
   },
   "source": [
    "The network is row ready to be trained. This is done using the `fit()` function in Keras (just like how you would do in scikit-learn). We also specify the number of epochs as 20 for a start. You can increase or decrease this later as deem fit. In one epoch, the whole of the training data will be fed to the network 20 while we will be using the test data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce69f0",
   "metadata": {
    "id": "64ce69f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=30, verbose=1, validation_data=(test_data, test_labels_one_hot), callbacks=[tensorboard_callback])\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41eae7",
   "metadata": {
    "id": "fd41eae7"
   },
   "source": [
    "Next, we check the performance on the unseen test data using the evaluate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b7dc9",
   "metadata": {
    "id": "a82b7dc9"
   },
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618c65a",
   "metadata": {
    "id": "0618c65a"
   },
   "source": [
    "Start TensorBoard within the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a745ada",
   "metadata": {
    "id": "4a745ada"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d58bc",
   "metadata": {
    "id": "635d58bc"
   },
   "source": [
    "## Inference on an image\n",
    "\n",
    "We have seen previously that the first image in the test set is the number 7. Let us see what the model predicts.\n",
    "\n",
    "The `predict()` method returns the probabilities (confidence level) of the different classes when performing the prediction. Typically, only the class with largest probability (most confident) is taken as the result. However, it is possible sometimes that the system intends to output a few top scoring classes (instead of just one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c294cd5",
   "metadata": {
    "id": "3c294cd5"
   },
   "outputs": [],
   "source": [
    "# Predict the probabilities for each class \n",
    "res = model.predict(test_data[[0],:])\n",
    "print(res)\n",
    "# Get the most likely class\n",
    "print(np.argmax(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399442a",
   "metadata": {
    "id": "c399442a"
   },
   "source": [
    "Finally, just to check on a concise summary of what your neural network model has, use `summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a2f29",
   "metadata": {
    "id": "f68a2f29",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35ee17",
   "metadata": {
    "id": "ca35ee17"
   },
   "source": [
    "## Extra Exercise: Labeled Faces in the Wild (LFW) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ca6f5",
   "metadata": {
    "id": "635ca6f5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people #dataset from sklearn\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=30, resize=0.4)\n",
    "\n",
    "for name in lfw_people.target_names:\n",
    "    print(name)\n",
    "    \n",
    "print(lfw_people.data.dtype)\n",
    "print(lfw_people.data.shape)\n",
    "print(lfw_people.images.shape)\n",
    "print(lfw_people.target.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc2e57",
   "metadata": {
    "id": "4dbc2e57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#im = np.reshape(lfw_people.data[30], (50, 37))\n",
    "\n",
    "# find person of index i\n",
    "idx = 15\n",
    "folks = lfw_people.data[np.where(lfw_people.target==idx)]\n",
    "\n",
    "from skimage.util import montage\n",
    "folks_3d = np.reshape(folks, (folks.shape[0], 50, 37))\n",
    "plt.imshow(montage(folks_3d), cmap='gray')\n",
    "plt.title(lfw_people.target_names[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372165f",
   "metadata": {
    "id": "4372165f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = lfw_people.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw_people.data, y, test_size=0.2, stratify=None)\n",
    "\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "dimData = np.prod(X_train.shape[1:])\n",
    "print(nClasses, dimData)  #correct\n",
    "\n",
    "train_data = X_train.astype('float32')\n",
    "test_data = X_test.astype('float32')\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_labels_one_hot = to_categorical(y_train)\n",
    "test_labels_one_hot = to_categorical(y_test)\n",
    " \n",
    "# Show the category label after one-hot encoding\n",
    "print('Original label : ', y_train[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627a7ff",
   "metadata": {
    "id": "a627a7ff"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(dimData,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size=64, epochs=50, verbose=1, validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb4962",
   "metadata": {
    "id": "93bb4962"
   },
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CDS6334",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
