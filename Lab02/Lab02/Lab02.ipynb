{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69yUasLyi6iB"
   },
   "source": [
    "# Lab02 - Point-based Processing\n",
    "\n",
    "### CDS6334 Visual Information Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0vd31jwi6iJ"
   },
   "source": [
    "This lab introduces the concept of *point-based* processing. As before, this lab is primarily guided in many portions and there are sections with questions that you are attempt to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNxHiMMGi6iK"
   },
   "source": [
    "First, load the necessary libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3wYGEwpi6iL"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVRnHTE4i6iN"
   },
   "source": [
    "## I. Image Transformation\n",
    "\n",
    "Point-based processing involves the direct transformation of each pixel value in an image. An image $f(x,y)$ is said to have undergone a transformation $T$ to an output image $g(x,y)$. In other words, each pixel in $f$ is put thru a function $T$ to get a new value $g$:\n",
    "\n",
    "\\begin{equation}g(x,y)= T(f(x,y))\\end{equation}\n",
    "\n",
    "### A. Negative Image\n",
    "One of the simplest functions that we can apply to an image is the <b>negative function</b>. \n",
    "\n",
    "\\begin{equation}g=(L-1)-f\\end{equation}\n",
    "\n",
    "So each value is subtracted by 255. So what happens is that the lighter pixels become dark and the darker picture becomes light. And it results in image negative.\n",
    "\n",
    "We shall use the image of a pouting girl:\n",
    "<img src=\"pout.png\" style=\"width:150px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_jAeSmxi6iO"
   },
   "outputs": [],
   "source": [
    "pout = cv2.imread('pout.png',0) \n",
    "pout.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U402xRt-i6iO"
   },
   "outputs": [],
   "source": [
    "negpout = 255-pout   # 256-1-pout\n",
    "plt.imshow(pout, cmap='gray')\n",
    "plt.imshow(np.hstack((pout,negpout)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)#np.nan)   # this is to print full numpy array\n",
    "print(negpout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCIqS7NUi6iQ"
   },
   "source": [
    "### B. Log Transformation\n",
    "\n",
    "Non-linear functions can also be applied. They offer a lot more uses especially when the condition of the original image is poor to begin with. The <b>log transformation function</b> is one which is able to stretch the distribution of the pixels:\n",
    "\n",
    "\\begin{equation}\n",
    "g=c. \\text{log} (1+f)\n",
    "\\end{equation}\n",
    "\n",
    "Where g and f are the pixel values of the output and the input image and c is a constant. The value 1 is added to each of the pixel value of the input image because if there is a pixel intensity of 0 in the image, then log(0) is equal to infinity. So 1 is added, to make the minimum value at least 1.\n",
    "\n",
    "During log transformation, the dark pixels in an image are expanded as compared to the higher pixel values. The higher pixel values are kind of compressed in log transformation. This result in the following image enhancement.\n",
    "\n",
    "The value of c in the log transform adjust the kind of enhancement we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8rjCu0Hi6iR"
   },
   "outputs": [],
   "source": [
    "c = 25\n",
    "logpout = np.uint8(c*np.log(1.000001+pout))\n",
    "logpout\n",
    "print(logpout.dtype)\n",
    "plt.subplot(121), plt.imshow(pout, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(logpout, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxgcTBlzi6iS"
   },
   "source": [
    "### C. Gamma Correction\n",
    "\n",
    "<b>Gamma correction</b> is a nonlinear operation used to encode and decode luminance or tristimulus values in video or still image systems. Gamma correction is also known as the <b>Power Law Transform</b>. First, the image pixel intensities must be scaled from the range 0, 255 to 0, 1.0. From there, we obtain our output gamma corrected image by applying the following equation:\n",
    "\\begin{equation} g = c.f^{(1/\\gamma)} \\end{equation}\n",
    "\n",
    "where $f$ is the input image and $\\gamma$ is the gamma value. The output image, $f$ is then scaled back to the range 0-255.\n",
    "\n",
    "<b>The Reason of Gamma Correction</b>\n",
    "\n",
    "The reason we apply gamma correction is that our eyes perceive color and luminance differently than the sensors in a digital camera. When a sensor on a digital camera picks up twice the amount of photons, the signal is doubled. However, our eyes do not work like this. Instead, our eyes perceive double the amount of light as only a fraction brighter. Thus, while a digital camera has a linear relationship between brightness our eyes have a non-linear relationship. In order to account for this relationship, we apply gamma correction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2Awd2USi6iT"
   },
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # print(table)\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "pout\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131), plt.imshow(adjust_gamma(pout, 1), cmap='gray')\n",
    "plt.subplot(132), plt.imshow(adjust_gamma(pout, 0.5), cmap='gray')\n",
    "plt.subplot(133), plt.imshow(adjust_gamma(pout, 5),cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q0JgIwxi6iT"
   },
   "source": [
    "**Q1**: Apply the (1) <b>negative</b>, (2) <b>log transformation</b> and (3) <b>gamma</b> function to the following color image, \"parrot.png\". For log transformation, apply to the gray image of the parrot.<br>\n",
    "<img src=\"parrot.png\" style=\"width:250px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo06x1z8i6iU"
   },
   "source": [
    "**Q2**: Try to implement the following three functions on the `pout.png` image:<br>\n",
    "<img src=\"arithmetic-operations.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyzM_b1Ei6iU"
   },
   "outputs": [],
   "source": [
    "#Enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU5rYlsAi6iV"
   },
   "source": [
    "## II. Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyM2pEc5i6iV"
   },
   "source": [
    "An image histogram is typically a graphical plot that shows the frequency of occurrence (or distribution) of intensity levels in an image *(Note: Later, we will learn that histograms are simply a vector of count values that can be used for more higher-level tasks like representation and description.)* Two concepts are most important in a histogram:\n",
    "- BINS: the number of compartments we wish to use to group the intensity values into. Typically, we just use a bin for every intensity value (hence, 256 bins in total), or we can also use larger bins that can take a range of values, i.e. 16 bins for each 16 intensity values.\n",
    "- RANGE: the range of intensity values that you want to measure. Normally it's [0, 256]\n",
    "\n",
    "There are two functions that can be used to calculate histograms (one from OpenCV, the other from Numpy). Check out the documentation to find out more about the input parameters for [`cv2.calcHist`](https://docs.opencv.org/3.4.1/d6/dc7/group__imgproc__hist.html) and [`np.histogram`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_NsSe4Ui6iW"
   },
   "outputs": [],
   "source": [
    "pout = cv2.imread('pout.png', cv2.IMREAD_GRAYSCALE)\n",
    "hist0 = cv2.calcHist([pout],[0],None,[256],[0,256])    # using OpenCV function\n",
    "hist,bins = np.histogram(pout.ravel(),256,[0,256])     # using Numpy function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf_jYPYqi6iW"
   },
   "source": [
    "*Note: OpenCV function is faster (around 40x) than np.histogram(). So take this point into consideration when efficiency is a priority.*\n",
    "\n",
    "There are two ways to plot the histogram -- using Matplotlib and using OpenCV drawing functions. We will stick to using Matplotlib as it is more straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bld_FYai6iW"
   },
   "outputs": [],
   "source": [
    "# Using matplotlib\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(121), plt.imshow(pout, cmap='gray')\n",
    "plt.subplot(122), plt.hist(pout.ravel(),256,[0,256]); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMkYOqRni6iX"
   },
   "outputs": [],
   "source": [
    "def showImage(img, titlestr=\"\" ):\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  \n",
    "    plt.title(titlestr)\n",
    "    plt.show()\n",
    "    \n",
    "# Using OpenCV\n",
    "rf = cv2.imread('redflower.jpg')\n",
    "rf = cv2.cvtColor(rf, cv2.COLOR_BGR2RGB)  \n",
    "showImage(rf)\n",
    "plt.figure(figsize=(7,3))\n",
    "color = ('r','g','b')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([rf],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdlTUUgJi6iX"
   },
   "source": [
    "Noticed how the individual red, green and blue channels are distributed across the intensity values?\n",
    "Tinker with the number of bins to make more observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GngdLtOfi6iX"
   },
   "source": [
    "#### Application of Mask\n",
    "\n",
    "We used <b>cv2.calcHist()</b> to find the histogram of the full image. What if you want to find histograms of some regions of an image? Just create a mask image with white color on the region you want to find histogram and black otherwise. Then pass this as the mask.\n",
    "\n",
    "The mask is created in the following code snipplet. Complete the program to create and show the histogram with the mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36xlMl9Ni6iY"
   },
   "outputs": [],
   "source": [
    "# create a mask\n",
    "mask = np.zeros(rf.shape[:2], np.uint8)\n",
    "mask[50:150, 50:150] = 255\n",
    "masked_img = cv2.bitwise_and(rf,rf,mask = mask)\n",
    "\n",
    "# create and show the histogram with the mask\n",
    "showImage(masked_img)\n",
    "plt.figure(figsize=(7,3))\n",
    "color = ('r','g','b')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist(???) #enter your code here\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j_5JdUHi6iY"
   },
   "source": [
    "### Histogram Equalization\n",
    "\n",
    "Histogram equalization attemps to improve the distribution of intensity values in an image by equalizing or \"flattening\" the histogram as much as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bR3F0Vtni6iY"
   },
   "outputs": [],
   "source": [
    "hist,bins = np.histogram(pout.flatten(),256,[0,256])\n",
    "\n",
    "# this finds the cdf of the histogram \n",
    "cdf = hist.cumsum()      \n",
    "\n",
    "cdf_normalized = cdf * hist.max()/ cdf.max()     # normalize just to scale values down to show it clearly within histogram\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(pout.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4Zzl71qi6iZ"
   },
   "source": [
    "You can see that the histogram lies a narrow middle range. We need it to occupy the full spectrum. In pixel- or point-based image transformation, we need a transformation function which spreads out the current pixels in the middle range to both ends of the spectrum. That is what histogram equalization can do.\n",
    "\n",
    "Now, find the minimum histogram value (excluding 0) and apply a simple scaling of the CDF values back to the standard intensity range of [0, 255]. In theory, we normalize the CDF to [0, 1] before multiplying with the maximum of the range (L-1), which is 255. They will get us the same thing.\n",
    "\n",
    "The concept of a masked array from Numpy is used here, that is, all operations are performed on non-masked elements. You can read more about it from Numpy docs on [masked arrays](https://docs.scipy.org/doc/numpy/reference/maskedarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TL_7aAEi6iZ"
   },
   "outputs": [],
   "source": [
    "cdf_m = np.ma.masked_equal(cdf,0)\n",
    "#print(cdf)\n",
    "cdf_m = np.round((cdf_m - cdf_m.min())/(cdf_m.max()-cdf_m.min())*255)     # discretize back the CDF values to [0, 255]\n",
    "#print(cdf_m)\n",
    "new_cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "#print(new_cdf)\n",
    "\n",
    "# this does the mapping -- using the scaled cdf to look for the new intensity values\n",
    "pout2 = new_cdf[pout]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9lCGcJFi6iZ"
   },
   "source": [
    "Use again the earlier code to draw the histogram and cdf plot together. Observe what happens to both the histogram and cdf plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpTITFHFi6ia"
   },
   "outputs": [],
   "source": [
    "hist2,bins = np.histogram(pout2.flatten(),256,[0,256])\n",
    "\n",
    "cdf2 = hist2.cumsum()\n",
    "\n",
    "cdf_normalized = cdf2 * hist2.max()/ cdf2.max()     # normalize just to scale values down to show it clearly within histogram\n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(pout2.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()\n",
    "plt.imshow(pout2, cmap='gray'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIVrkC_Bi6ia"
   },
   "source": [
    "OpenCV provides a function to perform histogram equalization, `equalizeHist`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oolXcfOwi6ib"
   },
   "outputs": [],
   "source": [
    "equalized = cv2.equalizeHist(pout)\n",
    "pout_stack = np.hstack((pout,equalized)) #stacking images side-by-side. Useful function!\n",
    "showImage(pout_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOmFiR8Mi6ic"
   },
   "source": [
    "**Q3**: What happens if you perform histogram equalization one more time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kl7xBSPhi6ic"
   },
   "outputs": [],
   "source": [
    "#Enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVyR3WnFi6id"
   },
   "source": [
    "**Q4. Histogram equalization on color images**. \n",
    "\n",
    "Perform histogram equalization on the following color image.\n",
    "\n",
    "<img src=\"landscape.jpg\" style=\"width:300px\">\n",
    "\n",
    "Display the original and equalized image along with the respective histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDYv2A2qi6id"
   },
   "source": [
    "## Additional Exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jkwl34YRi6ie"
   },
   "source": [
    "### Contrast Stretching\n",
    "\n",
    "Contrast stretching is a way to improve the contrast in an image by \"stretching\" the range of intensity values it contains to span a desired range of values. Typical usage is to stretch the low-contrast range to the full range of pixel values (0 to 255 or whichever range the image type concerned allows).\n",
    "\n",
    "It can be characterized by piecewise linear functions:\n",
    "<img src=\"piecewise-linear.png\" style=\"width:250px\">\n",
    "<br>\n",
    "\\begin{equation}y=\\frac{b_{i+1}-b_{i}}{a_{i+1}-a_{i}}(x-a_{i})+b_{i}\\end{equation}\n",
    "\n",
    "You can see that the drastic transformation occurs to the middle section of the original range; the narrow $a_2-a_3$ range is stretched to a much wider $b_2-b_3$ range. Meanwhile both ends of the original range is compressed to a slightly narrower output range.You can try to apply non-linear piecewise contrast stretching to the images above and compare with results of other types of enhancement techniques.\n",
    "\n",
    "**Q**. Write a function that that calculate the output pixel value based on a piecewise linear function specified by values $a_{1},a_{2},...$ and $b_{1},b_{2},...$. Test it out on the `pout.tif` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlE6vSali6ie"
   },
   "outputs": [],
   "source": [
    "#Enter code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Code Exercise\n",
    "\n",
    "This exercise is to get you familiarized with the format required of the code submission in the upcoming individual assignment. In the provided materials, there is a folder containing a small dataset of 4 degraded images with the corresponding high quality groundtruths. Try to design a function to enhance these degraded images and place the code in the `adjustContrast.py` file. To evaluate the performance of your enhancement, just run the accompanying `evaluateContrast.py` which will compare the results with the groundtruth using 3 evaluation metrics, Mean Absolute Error (MAE), Peak Signal-to-Noise Ratio (PSNR), and Strutural Similarity (SSIM). <br>\n",
    "\n",
    "In order for the codes to work, please pip install the `prettytable` package, and the evaluation results will be printed in your console."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CDS6334",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
